{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S2vJ0u9EOWah"
   },
   "source": [
    "![](cover.png)\n",
    "\n",
    "# 生成式對抗網路 - GAN\n",
    "\n",
    "## 介紹\n",
    "\n",
    "之前介紹的深度學習模型，包括MLP，CNN和RNN都還在判斷的範疇，但人類在學會『判斷』以後更進一步想達成的事就是『創作』，就好比你學會判斷各種不同畫家的風格以後，更難的一件事就是創作出跟畫家一樣風格，但是不一樣內容的畫。但如何讓電腦能夠創作呢？如果我們用之前整個機器學習的概念來說，也就是『利用大量的資料來做出公式』的概念來說，會變成如何呢？\n",
    "\n",
    "![圖:創作的概念](gan_1.png)\n",
    "\n",
    "我初步的想法會是這樣的，人類的創作就像是把一個『小小的靈感』擴充成為『最後的作品』這樣的過程，那我們一起來看一下裡面的幾個角色！\n",
    "\n",
    "1. 輸入(靈感): 這裡的輸入跟我們以前的神經網路的輸入不一樣，以前的輸入都是一個成品，但現在要是一個『靈感』，什麼叫做一個『靈感』呢，我不知道，但靈感對於我來說，就很像是一個『突然(隨機)冒出的想法』，那電腦可以不可以用一個『隨機小組合輸入』來模擬靈感這件事呢！好像可以，於是我們就將『靈感』代換成為『隨機的小組合輸入』(也許是100個位置的隨機數字)\n",
    "\n",
    "2. 模型(公式): 我們一再強調，模型就像是一個擬和『輸入』和『輸出』的『公式』，所以這裡我們可以選用之前教的所有創建『公式』的手段(e.g. MLP, CNN...)\n",
    "\n",
    "3. 輸出(作品): 最有問題的就是這裡了！我們在之前的深度學習大部分學習的是『監督式學習』，答案都是已經被標註上去，而我們可以透過答案來調整公式(梯度下降)，現在我們是無中生有，該如何判斷這是一個『對的作品呢』？\n",
    "\n",
    "![圖:放到深度學習最大的問題](gan_2.png)\n",
    "\n",
    "還好，感謝Ian Goodfellow對於這個問題的貢獻，在2014年(不久以前)的一個晚上，據傳他在跟朋友喝酒慶祝的時候，靈機一動，既然『深度神經網路』對於『判斷』已經非常好了，何不把『什麼是對的作品』這個問題交給另外一個神經網路呢？這個靈機一動的想法啟發了我們使用電腦創作的路途！於是我們叫這種『一個網路創作，一個網路分辨』的想法為 Generative Adversial Network(對抗式生成網路)，簡稱 GAN！\n",
    "\n",
    "![圖:GAN架構](gan_3.png)\n",
    "\n",
    "\n",
    "另外一個對於兩個神經網路好的比喻就是：『神經網路1』是一個『創作假畫的人』(創作家)，『神經網路2』是我們雇來『判斷畫真假的人』（鑑賞家)，如果今天我們創作出來的『假畫』能夠以假亂真，得到『鑑賞家』的『真(好)』的評價，就代表我們的『創作』已經跟真的沒兩樣，也就完成我們一開始的使命，讓電腦(神經網路1)創作！\n",
    "\n",
    "## 訓練公式的步驟\n",
    "\n",
    "這裡就是比較特別的地方了！現在我們總共有兩個東西是需要訓練出來的，神經網路1(創作家)和神經網路2(鑑賞家)，以下我們先定義一下他們的任務 \n",
    "\n",
    "### 創作家任務\n",
    "\n",
    "1. 輸入 = 隨機輸入\n",
    "\n",
    "2. 期望輸出 = 鑑賞家網路的正面(1)評價\n",
    "\n",
    "### 鑑賞家任務\n",
    "\n",
    "1. 輸入 = 真(來自資料集) 和 假(來自創作家)的樣本\n",
    "\n",
    "2. 期望輸出 = 1(資料集) 和 0(創作家)\n",
    "\n",
    "### 訓練步驟\n",
    "\n",
    "訓練步驟就比較麻煩一點了，雖然我們想直接訓練上面的架構網路，但如果鑑賞家沒經過一點訓練就直接接上去的話，會根本分不出真假，但也不能一開始就接上一個無敵的鑑賞家，因為這樣會讓創作家根本不知道怎麼靠近真的作品(不管好不好都被無情打槍)，於是我們採取的方式是，兩邊都一點點的進步，直到最後達成一個平衡！\n",
    "\n",
    "1. 步驟1: (訓練鑑賞家) 先稍微訓練一下鑑賞家\n",
    "2. 步驟2: (訓練創作家) 把鑑賞家接到創作家後面，開始訓練創作家，這裡要記得我們這時候是訓練創作家，所以鑑賞家要固定所有的weights不動\n",
    "3. 回到步驟1\n",
    "\n",
    "## ✔ Step1. 準備資料集\n",
    "\n",
    "我們使用keras內建的mnist(數字)資料集，但由於會上網去下載，MAC電腦的使用者如果沒加入此兩行會出現 SSL:CERTIFICATE_VERIFY_FAILED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nB1PxYrIOTvS"
   },
   "outputs": [],
   "source": [
    "# 我們會從https下載資料庫, MAC電腦需要加入以下兩行, 才不會把對方的ssl憑證視為無效\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "讀取mnist資料集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mBdTlq0BOfHN"
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "# 回傳值: ((訓練特徵, 訓練目標), (測試特徵, 測試目標))\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "看一下mnist資料集的維度，總共60000筆 28 * 28 的黑白數字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "bRzT7lfkOhbd",
    "outputId": "9e732913-0cb0-4b08-b40a-ebcc1ac16aa1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "這裡比較要注意一點，我們會比較傾向於把圖片標準化到 -1和1 區間 而不是 0和1 區間，主因是因為 0和1 並不是中心點(0)對稱的，我們更希望我們的輸入和輸出都是中心點對稱的！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MWKAkaD2Ojft"
   },
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "# reshape讓他從 32 * 32變成 784 * 1的一維陣列\n",
    "# 讓我們標準化到-1~1區間\n",
    "# 要不要轉化成為float32都可以\n",
    "x_train_shaped = (x_train.reshape(60000, 784).astype(\"float32\") - 127.5)/127.5\n",
    "x_test_shaped = (x_test.reshape(10000, 784).astype(\"float32\") - 127.5)/127.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F1__dR7zOkz1"
   },
   "source": [
    "## ✔ Step2. 建立創作家\n",
    "\n",
    "我們做一個跟我們以前反向的深度網路，神經元隨著層數越來越大，最後的神經元數目要等於你要創作的圖片的維度(28 x 28)，我們希望最後的輸出是在 -1和1區間，所以我們使用tanh函數當成我們最後的激活函數\n",
    "\n",
    "![圖:tanh和sigmoid的比較](tanh.jpg)\n",
    "\n",
    "### BatchNormalization\n",
    "\n",
    "這裡我們使用了一個在原始GAN論文裡沒使用的技巧。Batch Normalization！\n",
    "\n",
    "因為GAN極其的脆弱，因為是一個反向的神經網路，所以可以想見一點影響都會被擴大，有可能會完全偏離中心點，導致正很大或負很大，正很大的時候relu激活函數完全不會截斷(變成0)，負很大的時候relu則會直接讓神經元『死掉』，意味著所有輸出都是0，梯度也全部都是0，導致我們完全脫離不出死亡區！\n",
    "\n",
    "\n",
    "這裡我們想起了一件事，我們再傳入我們的圖片的時候，通常會喜歡做一次標準化，優點是可以好好配合隨機的Weights，不會隨意的亂走！那第二層以後的輸出可以不可以也做出標準化，將他移到比較好處理的範圍呢？答案當然是可以的，而且由於我們是批次(batch)的訓練，所以我們也希望可以直接對整個batch做一次標準化就好\n",
    "\n",
    "![圖: Batch Normalization公式](bn.png)\n",
    "\n",
    "上面是Batch Normalization的公式，前三行很簡單，就是普通的標準化，平移到均值為0的位置，縮放成標準差爲1，變成一個常態的分布\n",
    "\n",
    "整個精華在第四行，因為我們的特徵可能本來就不該均值0和標準差1啊，所以他加了個縮放參數在這裡($\\gamma$ 和 $\\beta$)。而且讓神經網路自己學習這兩個參數該是多少！\n",
    "\n",
    "如果用白話文解釋Batch Normalization就是：對每一層都做出我們習慣的標準化 -1 和 1 的區間，不過考慮的圖不是只有現在這張圖，而是這個batch所有的圖！\n",
    "\n",
    "至於Batch Normalization(BN)放置的位置有兩種說法：\n",
    "\n",
    "1. Conv(卷積) - BN - Relu(非線性激活): 讓激活函數吃到的input是可以比較好的對應到激活和非激活區域\n",
    "\n",
    "2. Conv(卷積) - Relu(非線性激活) - BN: 讓卷積層吃到的input都是標準化的結果\n",
    "\n",
    "兩種方式都有其支持者，我個人喜好第二種方式，因為會比較像是我們對於第一層輸入的處理方式，讀者如果喜歡第一種方式也可以自行替換！\n",
    "\n",
    "### 靈感\n",
    "\n",
    "別忘了我們說的靈感，所以我們期待會有一個100位置的任意輸入，然後把它擴充成為 28 $\\times$ 28 的圖片，你會發現，其實我們創建出來的就是一個反向的MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "colab_type": "code",
    "id": "xqQS0y4DOwoK",
    "outputId": "d13152c6-039e-4ddb-e4b3-f98352e47d63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 256)               25856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 784)               402192    \n",
      "=================================================================\n",
      "Total params: 562,704\n",
      "Trainable params: 561,168\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, BatchNormalization\n",
    "\n",
    "# Generator: 反向MLP\n",
    "# 隨機輸入的位置個數\n",
    "random_dim = 100\n",
    "# 這裡我採用每一層是上一層的兩倍神經元(類似VGG)的概念\n",
    "# 並不是一定, 讀者可以根據自己的喜好調整\n",
    "generator = Sequential()\n",
    "generator.add(Dense(256, input_dim=random_dim, \n",
    "                    activation='relu'))\n",
    "# 加上BN, 讓每一層輸入都標準化過\n",
    "generator.add(BatchNormalization())\n",
    "generator.add(Dense(512, activation='relu'))\n",
    "generator.add(BatchNormalization())\n",
    "generator.add(Dense(784, activation='tanh'))\n",
    "# 我們從不單獨訓練generator, 只會接起來訓練, 所以不compile\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xhxizvefOy8q"
   },
   "source": [
    "## ✔ Step3. 建立鑑賞家\n",
    "\n",
    "一個專門來負責看揪出創作家創造的假作品的鑑賞家，我使用最簡單的MLP當作我們鑑賞家。這裡我們使用大家習慣的MLP加上Dropout(0.25)來當鑑賞家。\n",
    "\n",
    "♥ Dropout(0.25 到 0.5)複習: 每一次都隨機留下這一層的 $\\frac14$ - $\\frac12$ 的神經元，目的是為了避免所有判斷都集中在某些神經元，導致過擬和，你可以想像成就像隨機森林一樣，最後的判斷是好幾顆『略有不同』的決策樹的平均，以經驗來說， $\\frac14$ - $\\frac12$ 的Dropout Rate是比較佳的選擇"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381
    },
    "colab_type": "code",
    "id": "eKGhP_lkO4Tp",
    "outputId": "ea83bcd0-969d-42cc-9ac6-0ad49e32c997"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_11 (Dense)             (None, 1024)              803840    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 1,460,225\n",
      "Trainable params: 1,460,225\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dropout\n",
    "\n",
    "discriminator = Sequential()\n",
    "discriminator.add(Dense(1024, input_dim=784, \n",
    "                        activation='relu'))\n",
    "# 加上Dropout防止過擬和\n",
    "discriminator.add(Dropout(0.25))\n",
    "discriminator.add(Dense(512, activation='relu'))\n",
    "discriminator.add(Dropout(0.25))\n",
    "discriminator.add(Dense(256, activation='relu'))\n",
    "discriminator.add(Dropout(0.25))\n",
    "# 最後只輸出一個神經元, 意味著是真的機率, 所以採用sigmoid函數\n",
    "# 1: 100%為真 \n",
    "# 0:   0%為真(偽)\n",
    "discriminator.add(Dense(1, activation='sigmoid'))\n",
    "# 在我們的兩個步驟的第一步, 會訓練discrinminator, 所以需要compile\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=\"adam\")\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "boSPqEy_PA9w"
   },
   "source": [
    "## ✔ Step4. 組合網路\n",
    "\n",
    "別忘了我們步驟二要訓練的對象是generator，在這裡幫你回憶一下\n",
    "\n",
    "![圖: 第二步驟要訓練的對象](gan_3.png)\n",
    "\n",
    "所以我們要把discriminator和generator接起來，不過記得這時候要把discriminator.trainable設定成False，也就是所有的weights固定住，不讓他有任何的改變，你說這樣會不會影響到我們上面的discriminator，這裡的trainable是在模型一compile就會決定了，所以上面的discriminator依然是trainable = True(已經compile過)，這裡千千萬萬要注意compile前要把該設置的trainable完成設定，不然會一點效用都沒有，你可以看到我們下面模型的Non-trainable params就會多出固定住的weights數！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 243
    },
    "colab_type": "code",
    "id": "nsBSSwwtO-7w",
    "outputId": "ce0dfa6d-cb91-4591-84f3-bef92a057fe9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "sequential_3 (Sequential)    (None, 784)               562704    \n",
      "_________________________________________________________________\n",
      "sequential_4 (Sequential)    (None, 1)                 1460225   \n",
      "=================================================================\n",
      "Total params: 2,022,929\n",
      "Trainable params: 561,168\n",
      "Non-trainable params: 1,461,761\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "# 先將discriminator固定住\n",
    "discriminator.trainable = False\n",
    "# 這裡我們要組合模型必須使用Model來創建\n",
    "# 先準備Input Layer\n",
    "gan_input = Input(shape=(random_dim,))\n",
    "# 經過創作家\n",
    "x = generator(gan_input)\n",
    "# 再將輸出當成鑑賞家的輸入\n",
    "gan_output = discriminator(x)\n",
    "# 創建最後的模型, 輸入和輸出依照上面的圖設定好\n",
    "gan = Model(inputs=gan_input, outputs=gan_output)\n",
    "gan.compile(loss='binary_crossentropy', optimizer=\"adam\")\n",
    "gan.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ✔ Step5. 開始訓練\n",
    "\n",
    "這裡由於我們的模型訓練步驟較為繁瑣，所以我們自行定義我們的訓練步驟"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 537
    },
    "colab_type": "code",
    "id": "xmDhpLtwPB6w",
    "outputId": "82de9dfc-3b3f-4e7f-9c59-ef0e75710564"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- epoch 10 ---------------\n",
      "Discriminator loss: 0.5364364385604858\n",
      "Generator loss: 1.1371174\n",
      "--------------- epoch 20 ---------------\n",
      "Discriminator loss: 0.5408498048782349\n",
      "Generator loss: 1.0774026\n",
      "--------------- epoch 30 ---------------\n",
      "Discriminator loss: 0.5115633606910706\n",
      "Generator loss: 1.1282328\n",
      "--------------- epoch 40 ---------------\n",
      "Discriminator loss: 0.5817527174949646\n",
      "Generator loss: 1.208801\n",
      "--------------- epoch 50 ---------------\n",
      "Discriminator loss: 0.5543758869171143\n",
      "Generator loss: 1.1865461\n",
      "--------------- epoch 60 ---------------\n",
      "Discriminator loss: 0.5335442423820496\n",
      "Generator loss: 1.1673869\n",
      "--------------- epoch 70 ---------------\n",
      "Discriminator loss: 0.551646888256073\n",
      "Generator loss: 1.1927693\n",
      "--------------- epoch 80 ---------------\n",
      "Discriminator loss: 0.5925135612487793\n",
      "Generator loss: 1.1967777\n",
      "--------------- epoch 90 ---------------\n",
      "Discriminator loss: 0.5677541494369507\n",
      "Generator loss: 1.1523602\n",
      "--------------- epoch 100 ---------------\n",
      "Discriminator loss: 0.5547364950180054\n",
      "Generator loss: 1.0822356\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# batch: 200個圖片做一次梯度更新\n",
    "batch_size = 200\n",
    "# epoch: 總共看過 100次資料集\n",
    "epoch_count = 100\n",
    "# range會幫我們產生 0~99 的數字\n",
    "for epoch in range(0, epoch_count):\n",
    "    for batch_count in range(0, 300):\n",
    "        # 隨機出200個0-59999(x_train.shape[0] - 1)的整數\n",
    "        # 這裡要注意一下np.random.randint的第二個數字是不包括的\n",
    "        idx = np.random.randint(0, x_train.shape[0], batch_size)\n",
    "        # 拿出對應的圖片\n",
    "        imgs = x_train_shaped[idx]\n",
    "        # 準備好200個1\n",
    "        valid = np.ones((batch_size, 1))\n",
    "        # 準備好200個0\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "        # 步驟0: 隨機靈感(利用常態分布來產生)\n",
    "        noise = np.random.normal(0, 1, (batch_size, random_dim))\n",
    "        gen_imgs = generator.predict(noise)\n",
    "\n",
    "        # 步驟1-1:讓鑑賞家鑑賞對的image\n",
    "        d_loss_real = discriminator.train_on_batch(imgs, valid)\n",
    "        # 步驟1-2:讓鑑賞家鑑賞錯的image\n",
    "        d_loss_fake = discriminator.train_on_batch(gen_imgs, fake)\n",
    "        # loss為上方兩個小步驟平均\n",
    "        d_loss = (d_loss_real + d_loss_fake) / 2\n",
    "\n",
    "        # 重新準備一次靈感\n",
    "        noise = np.random.normal(0, 1, (batch_size, random_dim))\n",
    "        # 步驟2:訓練創作家的創作能力\n",
    "        # 因為創作者希望他的作品能被discriminator視為真, 所以傳遞valid進去\n",
    "        # 讓generator的weight可以往對的方向調整\n",
    "        g_loss = gan.train_on_batch(noise, valid)\n",
    "    # 因為100epoch印製起來太多, 所以我十個印一次\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        dash = \"-\" * 15\n",
    "        print(dash, \"epoch\", epoch + 1, dash)\n",
    "        print(\"Discriminator loss:\", d_loss)\n",
    "        print(\"Generator loss:\", g_loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面的訓練大概執行了數輪，約500 - 1000次的epoch後，我們得到以下的結果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rYl76VHlPKpn"
   },
   "source": [
    "## ✔ Step6. 訓練結果\n",
    "\n",
    "你發現在鑑賞家的幫助下，我們訓練出來的創作家創造的數字已經有模有樣了，有些數字已經看起來非常的真實了！但是我們的數字四周有雜點，這是因為就算有這些雜點，鑑賞家依舊會將之判定為真，這是我們後面要探討的問題！但想必你已經開始懂了GAN的整個概念了！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185
    },
    "colab_type": "code",
    "id": "sPdjF5tVPJ2v",
    "outputId": "5b862861-c5b6-4ea3-fd79-3197a3936c62"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAy0AAACnCAYAAAAc07MlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n1dySi92NBQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1008x1008 with 5 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# 拿出5個examples\n",
    "examples = 5\n",
    "# 準備五個靈感\n",
    "noise = np.random.normal(0, 1, (examples, random_dim))\n",
    "# 使用創作者開始創作\n",
    "gen_imgs = generator.predict(noise)\n",
    "\n",
    "# 這裡要注意一下, 必須讓-1-1回到0-1才能被正確印出來\n",
    "gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "# reshape成為圖片\n",
    "gen_imgs = gen_imgs.reshape(examples, 28, 28)\n",
    "# 設定一下完整畫布大小\n",
    "plt.figure(figsize = (14, 14))\n",
    "for i in range(0, examples):\n",
    "    # 將大圖分成1 * 5五小圖, 編號分別為\n",
    "    # 1, 2, 3, 4, 5\n",
    "    # 所以i必須+1來得到相對應的小圖\n",
    "    plt.subplot(1, examples, i + 1)\n",
    "    # 不打印座標軸\n",
    "    plt.axis('off')\n",
    "    # 秀出圖片\n",
    "    plt.imshow(gen_imgs[i], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Drive儲存\n",
    "\n",
    "如果你使用的是Colab，但由於Colab每次的機器都是一次性的，所以要記得儲存在自己的Google Drive才可以保存！可以mount後做出儲存，mount就像插入一個光碟片，我將我的google drive插入後命名為gdrive，那大家預設的使用路徑都在My Drive裡，所以請創好/keras/gan資料夾即可儲存！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "2S1UZuhGkYf9",
    "outputId": "27a67955-ecf3-4909-faaf-9a0b644685e1"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/gdrive')\n",
    "generator.save('/gdrive/My Drive/keras/gan/gan_gen.h5')\n",
    "discriminator.save('/gdrive/My Drive/keras/gan/gan_dis.h5')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "GAN_colab.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
